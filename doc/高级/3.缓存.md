## 一、缓存

### 1 简介

1、为什么要使用缓存？

为了提升系统的性能，我们一般会将部分数据放入到缓存中，加速访问，而db承担数据落盘的工作。

2、哪些数据适合存放到缓存？

- 及时性、数据一致性要求不高的。
- 访问量大且更新频率不高的数据(读多、写少)。

### 2 缓存实现

#### 2.1 缓存的处理逻辑

![image-20210525210337883](https://gitee.com/code1997/blog-image/raw/master/gulimall/02high/image-20210525210337883.png)

#### 2.2 缓存实现方式

##### 2.2.1 本地缓存

> 使用一个map来实现数据的缓存。

```java
static Map<String, Map<String, List<Catalog2Vo>>> cache = new HashMap<>();

/**
 * 优化：将多次查询数据库转变为查询一次。
 */
@Override
public Map<String, List<Catalog2Vo>> getCatalogJson() {
    if (cache.containsKey("catalogJson")) {
        return cache.get("catalogJson");
    }
    List<CategoryEntity> categoryEntities = this.baseMapper.selectList(new QueryWrapper<>());
    //1.查出所有一级分类
    List<CategoryEntity> level1Categorys = getCategoryByParentCid(categoryEntities, 0L);
    Map<String, List<Catalog2Vo>> catalogJson = level1Categorys.stream().collect(Collectors.toMap(entity -> entity.getCatId().toString(), entity -> {
        //查到一级分类的所有二级分类
        List<CategoryEntity> category2Entities = getCategoryByParentCid(categoryEntities, entity.getParentCid());
        List<Catalog2Vo> level2Categorys = null;
        if (category2Entities != null) {
            level2Categorys = category2Entities.stream().map(entity2 -> {
                //查出当前分类的二级分类
                //查出当前二级分类的三级分类
                List<CategoryEntity> category3Entities = getCategoryByParentCid(categoryEntities, entity2.getParentCid());
                List<Catalog2Vo.Catalog3Vo> level3Categorys = null;
                if (category3Entities != null) {
                    level3Categorys = category3Entities.stream().map(entity3 -> new Catalog2Vo.Catalog3Vo(entity2.getCatId().toString(), entity3.getCatId().toString(), entity3.getName())).collect(Collectors.toList());
                }
                return new Catalog2Vo(entity.getCatId().toString(), level3Categorys, entity2.getCatId().toString(), entity2.getName());
            }).collect(Collectors.toList());
        }

        return level2Categorys;
    }));
    cache.put("catalogJson", catalogJson);
    return catalogJson;
}
```

优点：

- 实现起来比较简单。
- 效率很高。
- 单机的情况下是可以的。

缺点：

- 对于分布式的情况下，存在数据一致性，本地缓存无法很好的适用。
- 容量存在限制。

##### 2.2.2 redis中间件

> 使用缓存中间件：redis，memcache等，这里以redis来实现。

1、导入依赖

```xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-data-redis</artifactId>
    <exclusions>
        <exclusion>
            <groupId>io.lettuce</groupId>
            <artifactId>lettuce-core</artifactId>
        </exclusion>
    </exclusions>
</dependency>
<dependency>
    <groupId>redis.clients</groupId>
    <artifactId>jedis</artifactId>
</dependency>
```

- 排除lettuce-core：存在堆外内存溢出的原因。
- 使用jedis替换，导入jedis的jar包即可。

2、配置端口等信息

```yaml
spring:
  redis:
    host: 192.168.134.151
    port: 6379
```

3、使用RedisTemplate来进行操作

```java
/**
 * 优化：使用缓存，来减少与数据库的交互。
 * todo:会产生堆外内存溢出，OutOfDirectMemoryError
 * 原因：springboot2.0以后，使用lettuce来作为操作redis的客户端，它使用netty来进行网络通信，主要原因是lettuce的原因，
 * 如果没有指定堆外内存，默认使用的-Xmx的配置，可以使用-Dio.netty.maxDirectMemory只去调大堆外内存。
 * 解决方案：
 *   1）升级lettuce客户端：但是目前还没有十分稳定的客户端。
 *   2）却换jedis作为客户端：长久没有更新，但是可以这样使用。
 */
@Override
public Map<String, List<Catalog2Vo>> getCatalogJson() {
    String catalogJson = stringRedisTemplate.opsForValue().get("catalogJson");
    if (!StringUtils.isEmpty(catalogJson)) {
        return JSON.parseObject(catalogJson, new TypeReference<Map<String, List<Catalog2Vo>>>() {
        });
    }
    Map<String, List<Catalog2Vo>> catalogJsonFromDb = getCatalogJsonFromDb();
    //将对象转化为json放到缓存中:可以兼容其他语言和平台
    String jsonString = JSONObject.toJSONString(catalogJsonFromDb);
    stringRedisTemplate.opsForValue().set("catalogJson", jsonString);
    return catalogJsonFromDb;
}

/**
 * 从数据库中查询并封装数据。
 */
private Map<String, List<Catalog2Vo>> getCatalogJsonFromDb() {
    List<CategoryEntity> categoryEntities = this.baseMapper.selectList(new QueryWrapper<>());
    //1.查出所有一级分类
    List<CategoryEntity> level1Categorys = getCategoryByParentCid(categoryEntities, 0L);
    return level1Categorys.stream().collect(Collectors.toMap(entity -> entity.getCatId().toString(), entity -> {
        //查到一级分类的所有二级分类
        List<CategoryEntity> category2Entities = getCategoryByParentCid(categoryEntities, entity.getParentCid());
        List<Catalog2Vo> level2Categorys = null;
        if (category2Entities != null) {
            level2Categorys = category2Entities.stream().map(entity2 -> {
                //查出当前分类的二级分类
                //查出当前二级分类的三级分类
                List<CategoryEntity> category3Entities = getCategoryByParentCid(categoryEntities, entity2.getParentCid());
                List<Catalog2Vo.Catalog3Vo> level3Categorys = null;
                if (category3Entities != null) {
                    level3Categorys = category3Entities.stream().map(entity3 -> new Catalog2Vo.Catalog3Vo(entity2.getCatId().toString(), entity3.getCatId().toString(), entity3.getName())).collect(Collectors.toList());
                }
                return new Catalog2Vo(entity.getCatId().toString(), level3Categorys, entity2.getCatId().toString(), entity2.getName());
            }).collect(Collectors.toList());
        }
        return level2Categorys;
    }));
}

public List<CategoryEntity> getCategoryByParentCid(List<CategoryEntity> selectList, Long parentCid) {

    return selectList.stream().filter(categoryEntity -> categoryEntity.getParentCid() == parentCid).collect(Collectors.toList());
}
```

4、进行压力测试

吞吐量大概为80，比起之前提高了很多。

#### 2.3 缓存失效问题

##### 2.3.1 缓存穿透

1、什么是缓存穿透？

指查询一个一定不存在的数据，由于缓存是不命中的，将去查询数据库，但是数据库也无此记录，我们没有将null写入缓存，这将导致这个不存在数据每次请求都要到存储层进行查询，失去了缓存的意义。

2、有什么风险？

利用不存在的数据进行攻击，数据库的瞬时压力增大，最终导致数据库崩溃。

3、如何解决

null结果进行缓存，并加入短暂的过期时间。

##### 2.3.2 缓存雪崩

1、什么是缓存雪崩？

我们设置缓存的时候key采用相同的过期时间，导致缓存在某一刻同时失效，请求全部转发到DB，DB瞬时压力过重雪崩。

2、解决方式

我们设置缓存的时候key随机一个过期时间，这样会导致缓存集体失效的概率降低，很难引发集体失效的事件。

##### 2.3.3 缓存击穿

1、什么是缓存击穿？

对于一些设置了过期时间的key，这些key可能在某个事件被超高并发的访问，是一种非常热点的数据。如果整个key在大量请求同时进来前正好失效，那么所有对这个key的数据的查询都落到db，我们称之为缓存击穿。

2、解决方式

加锁，大并发只让一个人去查询，其他人等待，查到之后释放锁，其他人获取到锁，先查缓存，存在数据，就不会继续查询db。

#### 2.4 解决缓存失效

1、代码实现

```java
/**
     * 缓存穿透：空结果缓存。
     * 缓存雪崩：设置过期事件。
     * 缓存击穿：加锁：同步代码块,同步方法或者ReenTrantLock
     */
@Override
public Map<String, List<Catalog2Vo>> getCatalogJson() {
    String catalogJson = stringRedisTemplate.opsForValue().get("catalogJson");
    if (!StringUtils.isEmpty(catalogJson)) {
        return JSON.parseObject(catalogJson, new TypeReference<Map<String, List<Catalog2Vo>>>() {
        });
    }
    System.out.println("缓存不命中，准备查询数据库");
    synchronized (this) {
        Map<String, List<Catalog2Vo>> catalogJsonFromDb = getCatalogJsonFromDb();
        //将对象转化为json放到缓存中:可以兼容其他语言和平台
        String jsonString = JSONObject.toJSONString(catalogJsonFromDb);
        stringRedisTemplate.opsForValue().set("catalogJson", jsonString, 1, TimeUnit.DAYS);
        return catalogJsonFromDb;
    }
}

/**
     * 从数据库中查询并封装数据：双重check
     */
private Map<String, List<Catalog2Vo>> getCatalogJsonFromDb() {
    String catalogJson = stringRedisTemplate.opsForValue().get("catalogJson");
    if (!StringUtils.isEmpty(catalogJson)) {
        return JSON.parseObject(catalogJson, new TypeReference<Map<String, List<Catalog2Vo>>>() {
        });
    }
    System.out.println("查询数据库----");
    List<CategoryEntity> categoryEntities = this.baseMapper.selectList(new QueryWrapper<>());
    //1.查出所有一级分类
    List<CategoryEntity> level1Categorys = getCategoryByParentCid(categoryEntities, 0L);
    return level1Categorys.stream().collect(Collectors.toMap(entity -> entity.getCatId().toString(), entity -> {
        //查到一级分类的所有二级分类
        List<CategoryEntity> category2Entities = getCategoryByParentCid(categoryEntities, entity.getParentCid());
        List<Catalog2Vo> level2Categorys = null;
        if (category2Entities != null) {
            level2Categorys = category2Entities.stream().map(entity2 -> {
                //查出当前分类的二级分类
                //查出当前二级分类的三级分类
                List<CategoryEntity> category3Entities = getCategoryByParentCid(categoryEntities, entity2.getParentCid());
                List<Catalog2Vo.Catalog3Vo> level3Categorys = null;
                if (category3Entities != null) {
                    level3Categorys = category3Entities.stream().map(entity3 -> new Catalog2Vo.Catalog3Vo(entity2.getCatId().toString(), entity3.getCatId().toString(), entity3.getName())).collect(Collectors.toList());
                }
                return new Catalog2Vo(entity.getCatId().toString(), level3Categorys, entity2.getCatId().toString(), entity2.getName());
            }).collect(Collectors.toList());
        }
        return level2Categorys;
    }));

}

public List<CategoryEntity> getCategoryByParentCid(List<CategoryEntity> selectList, Long parentCid) {

    return selectList.stream().filter(categoryEntity -> categoryEntity.getParentCid() == parentCid).collect(Collectors.toList());
}
```

2、压力测试

单机版确实可以实现只查询一次数据的效果。

注意：查询数据库和redis中设置值一定要是原子性的操作。

3、存在的问题

问题：this只是jvm层次的一个对象，synchronized是jvm层次的单机锁，在分布式的情况下，存在几个机器就存在几个锁，锁不住整个服务。

解决：使用分布式锁--redisson。

4、模块设置

![image-20210525234207601](https://gitee.com/code1997/blog-image/raw/master/gulimall/02high/image-20210525234207601.png)

5、压力测试

现象：每一个服务都会查询一次数据库，和之前的分析结论一致。

### 3 分布式锁

> 只有一个位置，使用占位的思想。

#### 3.1 实现方式

- 使用setnx+lua：`key`设置值为`value`，如果`key`不存在，这种情况下等同[SET](http://www.redis.cn/commands/set.html)命令。 当`key`存在时，什么也不做。`SETNX`是”**SET** if **N**ot e**X**ists”的简写。

- 使用封装好的redisson

#### 3.2 setnx+lua

> 锁的加锁，解锁都需要保证原子性，吞吐量：29.457

```java
    /**
     * 使用setnx来设置
     * 问题：
     * 1）如果业务代码出现异常，或者删除锁之前机器挂掉了，就会无法删除锁，产生死锁现象-->设置过期时间，注意需要原子性设置。
     * 2）但是设置过期时间，我们的业务代码处理过程很长，导致key过期也没有执行结束，这个时候，别的线程抢到锁。我们可能会删除别人设置的锁。
     * 3）给每个线程设置的值都不一样，删除的时候先进行检查，防止删除别人的锁，但是获取值，判断也成功了，删除之前，锁过期了，别人重新设置了锁，还会存在误删的情况。因此获取锁并删除也需要是一个原子操作。
     * 4）使用lua脚本来实现，防止误删，但是业务的执行时间未知，导致key自动续期实现起来十分困难。
     */
    @Override
    public Map<String, List<Catalog2Vo>> getCatalogJson() {
        String catalogJson = stringRedisTemplate.opsForValue().get("catalogJson");
        if (!StringUtils.isEmpty(catalogJson)) {
            return JSON.parseObject(catalogJson, new TypeReference<Map<String, List<Catalog2Vo>>>() {
            });
        }
        Map<String, List<Catalog2Vo>> catalogJsonFromDb = new HashMap<>();
        String lockValue = "lock_" + UUID.randomUUID();
        try {
            boolean lock = stringRedisTemplate.opsForValue().setIfAbsent("lock", lockValue, 30L, TimeUnit.SECONDS);
            //如果加锁失败就进行自旋重试
            while (!lock) {
                System.out.println("没有获取到锁，再次尝试获取");
                Thread.sleep(100);
                lock = stringRedisTemplate.opsForValue().setIfAbsent("lock", lockValue, 30L, TimeUnit.SECONDS);
            }
            System.out.println("缓存不命中，准备查询数据库");
            catalogJsonFromDb = getCatalogJsonFromDb();
            //将对象转化为json放到缓存中:可以兼容其他语言和平台
            String jsonString = JSON.toJSONString(catalogJsonFromDb);
            stringRedisTemplate.opsForValue().set("catalogJson", jsonString, 1, TimeUnit.DAYS);
        } catch (InterruptedException e) {
            log.error("出现了异常", e);
        } finally {
            /*String curlockValue = stringRedisTemplate.opsForValue().get("lock");
                if (lockValue.equals(curlockValue)) {
                stringRedisTemplate.delete("lock");
            }*/
            String lua = "if redis.call(\"get\",KEYS[1]) == ARGV[1]\n" +
                    "then\n" +
                    "    return redis.call(\"del\",KEYS[1])\n" +
                    "else\n" +
                    "    return 0\n" +
                    "end";
            //返回0，1：
            stringRedisTemplate.execute(new DefaultRedisScript<>(lua, Long.class), Collections.singletonList("lock"), lockValue);
        }
        return catalogJsonFromDb;
    }
```

#### 3.3 Redisson

> 封装好的基于redis实现的java版本分布式锁。
>
> 官方网站：https://github.com/redisson/redisson

##### 3.3.1 redisson原生

> 锁的使用：https://github.com/redisson/redisson/wiki/8.-分布式锁和同步器#82-公平锁fair-lock

1、导入依赖

```java
<dependency>
    <groupId>org.redisson</groupId>
    <artifactId>redisson</artifactId>
    <version>3.14.1</version>
</dependency>
```

2、配置redisson

```java
/**
 * 创建RedissonClient
 */
@Bean(destroyMethod = "shutdown")
public RedissonClient redissonClient() {
    Config config = new Config();
    config.useSingleServer().setAddress("192.168.134.151:6379");
    return Redisson.create(config);
}
```

3、简单的实验

lock的特点：

* 存在看门狗，可以给key自动续期，如果业务很长，运行期间自动给锁进行续期(默认30s)，不需要担心业务时间过长导致锁失效。
* 加锁的业务只要运行完成，就不会给当前所进行续期，即使不自动解锁，锁默认也在30s之后自动删除。

看门狗机制：

* 如果我们传递了超时时间，就发送redis执行脚本，进行占锁，默认超时就是我们指定的时间。
* 如果我们没有传递超时时间，就使用看门狗的默认时间[30s]，只要占锁成功，就会启动一个定时任务[30/3]，从新给锁进行续期。

```java
@GetMapping("hello")
@ResponseBody
public String hello() {
    //如果我们设置了超时时间，就不会自动续期，无论业务是否执行完成，锁就会被删除，一旦过期了，线程再次去删除锁的时候会报错。
    RLock lock = redissonClient.getLock("my-lock");
    lock.lock();
    try {
        System.out.println("加锁成功，执行业务代码<=="+Thread.currentThread().getId());
        Thread.sleep(30000);
    } catch (Exception e){

    }
    finally {
        System.out.println("释放锁<=="+Thread.currentThread().getId());
        lock.unlock();
    }
    return "hello";
}
```

##### 3.3.2 读写锁

> 写锁是一个互斥锁，读锁是一个共享锁，因此：读读共享，读写，写写互斥。

```java
@GetMapping("/write")
@ResponseBody
public String write() throws InterruptedException {
    String uuid = UUID.randomUUID().toString();
    RReadWriteLock readWriteLock = redissonClient.getReadWriteLock("read_write_lock");
    RLock writeLock = readWriteLock.writeLock();
    writeLock.lock();
    try {
        stringRedisTemplate.opsForValue().set("uuid", uuid);
        Thread.sleep(30000);
    } finally {
        writeLock.unlock();
    }
    return uuid;
}

@GetMapping("/read")
@ResponseBody
public String read(){
    RReadWriteLock readWriteLock = redissonClient.getReadWriteLock("read_write_lock");
    RLock readLock = readWriteLock.readLock();
    String uuid = "";
    readLock.lock();
    try {
        uuid = stringRedisTemplate.opsForValue().get("uuid");
    } finally {
        readLock.unlock();
    }
    return uuid;
}
```

写锁：互斥锁，只有一个可以加锁成功

![image-20210526222417505](https://gitee.com/code1997/blog-image/raw/master/gulimall/02high/image-20210526222417505.png)

读锁：共享锁，都可以加锁成功，当有读锁的时候写锁需要等待，当有写锁的时候，读也需要等待。

![image-20210526222736222](https://gitee.com/code1997/blog-image/raw/master/gulimall/02high/image-20210526222736222.png)

##### 3.3.3 闭锁-CountDownLatch

案例：门卫等着锁门，还剩三个人，当三个人走后，就锁们。

```java
@GetMapping("/closeDoor")
@ResponseBody
public String closeDoor() throws InterruptedException {
    RCountDownLatch countDownLatch = redissonClient.getCountDownLatch("countDownLatch");
    System.out.println("准备锁门！");
    countDownLatch.trySetCount(3);
    countDownLatch.await();
    System.out.println("锁门成功！");
    return "锁门成功";
}

@GetMapping("/go")
@ResponseBody
public String go() throws InterruptedException {
    RCountDownLatch countDownLatch = redissonClient.getCountDownLatch("countDownLatch");
    System.out.println("go!!!");
    countDownLatch.countDown();
    return "走一个";
}

执行效果：
准备锁门！
go!!!
go!!!
go!!!
锁门成功！
```

##### 3.3.4 信号量-Semaphore

案例：指定数量的信号量，acquire获取一个，release释放一个，可以用来做限流。

```java
@GetMapping("/park")
@ResponseBody
public String park() throws InterruptedException {
    RSemaphore semaphore = redissonClient.getSemaphore("semaphore");
    //获取一个信号:是一个阻塞的方法
    semaphore.acquire();
    // 不会进行阻塞式的等待
    // semaphore.tryAcquire();

    return "park";
}

@GetMapping("/unpark")
@ResponseBody
public String unpark() throws InterruptedException {
    RSemaphore semaphore = redissonClient.getSemaphore("semaphore");
    //释放一个信号
    semaphore.release();
    return "unpark";
}
```

##### 3.3.5 redisson实现分布式锁

1、缓存数据一致性解决方案：

- 双写模式：更新完成数据库之后需要同时更新缓存。

  ![image-20210526230805350](https://gitee.com/code1997/blog-image/raw/master/gulimall/02high/image-20210526230805350.png)

- 失效模式：更新完数据库之后删除缓存，等待下次查询等待更新。

  ![image-20210526231243328](https://gitee.com/code1997/blog-image/raw/master/gulimall/02high/image-20210526231243328.png)

无论是双写模式化石失效模式，都会导致缓存不一致的问题，多个实例进行更新会出错，如何处理？

- 如果是用户维度的数据(订单数据，用户数据)，并发量比较小的数据，不需要进行考虑，缓存加上过期时间，每隔一段时间触发读的主动更新即可。

- 如果是菜单，商品介绍等基础数据，可以使用canal订阅binlog的方式。

  ![image-20210526232504144](https://gitee.com/code1997/blog-image/raw/master/gulimall/02high/image-20210526232504144.png)

- 缓存数据+过期时间也是足够解决大部分业务对于缓存的要求。

- 通过加锁可以保证并发的读写，写写的时候按照顺序排好队，读读允许的情况下可以适应读写锁，如果业务不关心脏数据，允许临时脏数据可被忽略。

总结：

1. 如果数据可以存在一定的不一致情况，则给所有的缓存数据加上失效时间，保证每天拿到当前最新数据即可。
2. 对于允许存在一定脏数据，读多写少的情况下，可以考虑使用读写锁。
3. 遇到实时性、一致性要求高的数据，就应该查数据库，即使慢点。

### 4 Spring Cache

> 使用spring cache对我们代码进行修改。

#### 4.1 基本概念

##### 4.1.1 JSR107

Java Caching定义了5个核心接口，分别是==CachingProvider==,==CacheManager==, ==Cache==,==Entry== 和==Expiry==。

- CachingProvider定义了创建、配置、获取、管理和控制多个CacheManager。一个应用可 以在运行期访问多个CachingProvider。
- CacheManager定义了创建、配置、获取、管理和控制多个唯一命名的Cache，这些Cache 存在于CacheManager的上下文中。一个CacheManager仅被一个CachingProvider所拥有。
- Cache是一个类似Map的数据结构并临时存储以Key为索引的值。一个Cache仅被一个 CacheManager所拥有。
- Entry是一个存储在Cache中的key-value对。
- Expiry 每一个存储在Cache中的条目有一个定义的有效期。一旦超过这个时间，条目为过期 的状态。一旦过期，条目将不可访问、更新和删除。缓存有效期可以通过ExpiryPolicy设置。

##### 4.1.2 Spring缓存抽象

Spring从3.1开始定义了org.springframework.cache.Cache和org.springframework.cache.CacheManager接口来统一不同的缓存技术； 并支持使用JCache（JSR-107）注解简化我们开发；

- Cache接口为缓存的组件规范定义，包含缓存的各种操作集合；
- Cache接口下Spring提供了各种xxxCache的实现；如RedisCache，EhCacheCache , ConcurrentMapCache等；
- 每次调用需要缓存功能的方法时，Spring会检查检查指定参数的指定的目标方法是否 已经被调用过；如果有就直接从缓存中获取方法调用后的结果，如果没有就调用方法 并缓存结果后返回给用户。下次调用直接从缓存中获取。
- 使用Spring缓存抽象时我们需要关注以下两点；
  - 确定方法需要被缓存以及他们的==缓存策略==
  - 从缓存中读取之前缓存存储的数据

##### 4.1.3 缓存注解

| 注解           | 说明                                                         | 级别 |
| -------------- | :----------------------------------------------------------- | ---- |
| @Cacheable     | 主要针对方法配置，能够根据方法的请求参数对其结果进行缓存     | 方法 |
| @CacheEvict    | 清空缓存（缓存失效模式），一旦数据更新就清除缓存             | 方法 |
| @CachePut      | 保证方法被调用，又希望结果被缓存。（双写模式）               | 方法 |
| @EnableCaching | 开启基于注解的缓存                                           | 类   |
| @CacheConfig   | 共享的缓存配置                                               | 类   |
| @Caching       | 组合多个缓存注解                                             |      |
| Cache          | 缓存接口，定义缓存操作。实现有：RedisCache、EhCacheCache、 ConcurrentMapCache等 |      |
| CacheManager   | 缓存管理器，管理各种缓存（Cache）组件                        |      |
| keyGenerator   | 缓存数据时key生成策略                                        |      |
| serialize      | 缓存数据时value序列化策略                                    |      |

#### 4.2 使用

> @Cacheable:代表当前方法的结果需要缓存，如果缓存中存在，方法不调用，如果缓存中没有，会调用方法，然后将方法的返回缓存下

1、案例要求：

1. 定义生成的缓存使用的key，可以使用spel

2. 指定缓存的数据的存活时间，配置文件中设置ttl，默认未永不过期：spring.cache.redis.time-to-live=30000

3. 将数据保存为json格式，需要自定义缓存管理器：

  1. `CacheAutoConfiguration`自动配置了`RedisCacheConfiguration`

  2. `RedisCacheConfiguration`配置了`RedisCacheManager`，存在一个方法`determineConfiguration`

     ```java
     @Bean
     public RedisCacheManager cacheManager(RedisConnectionFactory redisConnectionFactory,
           ResourceLoader resourceLoader) {
        RedisCacheManagerBuilder builder = RedisCacheManager.builder(redisConnectionFactory)
              .cacheDefaults(determineConfiguration(resourceLoader.getClassLoader())); //决定使用什么配置
        List<String> cacheNames = this.cacheProperties.getCacheNames();
        if (!cacheNames.isEmpty()) {
           builder.initialCacheNames(new LinkedHashSet<>(cacheNames));
        }
        return this.customizerInvoker.customize(builder.build());
     }
     
     private org.springframework.data.redis.cache.RedisCacheConfiguration determineConfiguration(
           ClassLoader classLoader) {
         //如果存在redisCacheConfiguration就使用，如果没有就配置一个默认的
        if (this.redisCacheConfiguration != null) {
           return this.redisCacheConfiguration;
        }
        Redis redisProperties = this.cacheProperties.getRedis();
        org.springframework.data.redis.cache.RedisCacheConfiguration config = org.springframework.data.redis.cache.RedisCacheConfiguration
              .defaultCacheConfig();
        config = config.serializeValuesWith(
              SerializationPair.fromSerializer(new JdkSerializationRedisSerializer(classLoader)));
        if (redisProperties.getTimeToLive() != null) {
           config = config.entryTtl(redisProperties.getTimeToLive());
        }
        if (redisProperties.getKeyPrefix() != null) {
           config = config.prefixKeysWith(redisProperties.getKeyPrefix());
        }
        if (!redisProperties.isCacheNullValues()) {
           config = config.disableCachingNullValues();
        }
        if (!redisProperties.isUseKeyPrefix()) {
           config = config.disableKeyPrefix();
        }
        return config;
     }
     ```

   3.自己给容器中存放一个`RedisCacheConfiguration`即可。

   ```java
   @EnableConfigurationProperties(CacheProperties.class)
   @Configuration
   public class MyCacheConfig {
   
       /**
        * 配置文件中的内容会ttl设置失效。
        * 原因：缺少redisProperties：@ConfigurationProperties(prefix = "spring.cache")
        *                          public class CacheProperties {
        * 解决：
        *  1）装配CacheProperties.class：@EnableConfigurationProperties(CacheProperties.class)
        *  2）自动注入或者写入参数
        *
        */
       @Bean
       public RedisCacheConfiguration getRedisCacheConfiguration(CacheProperties cacheProperties){
           RedisCacheConfiguration redisCacheConfiguration = RedisCacheConfiguration.defaultCacheConfig();
           redisCacheConfiguration=redisCacheConfiguration.serializeKeysWith(RedisSerializationContext.SerializationPair.fromSerializer(new StringRedisSerializer()));
           redisCacheConfiguration=redisCacheConfiguration.serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(new GenericFastJsonRedisSerializer()));
           CacheProperties.Redis redisProperties = cacheProperties.getRedis();
           if (redisProperties.getTimeToLive() != null) {
               redisCacheConfiguration = redisCacheConfiguration.entryTtl(redisProperties.getTimeToLive());
           }
           if (redisProperties.getKeyPrefix() != null) {
               redisCacheConfiguration = redisCacheConfiguration.prefixKeysWith(redisProperties.getKeyPrefix());
           }
           if (!redisProperties.isCacheNullValues()) {
               redisCacheConfiguration = redisCacheConfiguration.disableCachingNullValues();
           }
           if (!redisProperties.isUseKeyPrefix()) {
               redisCacheConfiguration = redisCacheConfiguration.disableKeyPrefix();
           }
           return redisCacheConfiguration;
       }
   }
   ```

   4.属性配置

   ```properties
   spring.cache.type=redis
   #配置key的过期时间：毫秒为单位
   spring.cache.redis.time-to-live=3600000
   spring.cache.redis.key-prefix=CACHE_
   spring.cache.redis.use-key-prefix=true
   spring.cache.redis.cache-null-values=true
   ```

   5.业务代码：

   ```java
   /**
    * Cacheable:代表当前方法的结果需要缓存，如果缓存中存在，方法不调用，如果缓存中没有，会调用方法，然后将方法的返回缓存下来。
    * 1、定义生成的缓存使用的key，可以使用spel
    * 2、指定缓存的数据的存活时间,配置文件中设置ttl,默认未永不过期：spring.cache.redis.time-to-live=30000
    * 3、将数据保存为json格式，需要自定义缓存管理器
    */
   @Cacheable(value = {"category"}, key = "#root.method.name")
   @Override
   public List<CategoryEntity> getLevel1Categorys() {
       return this.baseMapper.selectList(new QueryWrapper<CategoryEntity>().eq("parent_cid", 0));
   }
   ```

2、缓存失效

```java
    /**
     * 级联更新所有关联的数据
     * 失效模式的展示：每当修改信息就删除缓存。key的表达式如果是纯字符串需要加上单引号。
     * 同时及进行多种缓存操作：
     * 方法1：@Caching来进行组合
     *     @Caching(evict = {
     *             @CacheEvict(value = "category", key = "'getLevel1Categorys'"),
     *             @CacheEvict(value = "category", key = "'getCatalogJson'")
     *     })
     * 方法2：使用直接删除某个分区下的所有数据。@CacheEvict(value = "category",allEntries = true)
     * 存储同一类型的数据，都可以指定称为一个分区。
     *
     * @param category :需要更新的分类信息
     */
    @CacheEvict(value = "category",allEntries = true)
    @Transactional
    @Override
    public void updateCascade(CategoryEntity category) {
        this.updateById(category);
        if (!StringUtils.isEmpty(category.getName())) {
            categoryBrandRelationService.updateCategory(category.getCatId(), category.getName());
        }
    }
```

当我们修改某个分类的时候，需要使多个缓存失效，如何实现：

```java
* 级联更新所有关联的数据
* 失效模式的展示：每当修改信息就删除缓存。key的表达式如果是纯字符串需要加上单引号。
* 同时及进行多种缓存操作：
* 方法1：@Caching来进行组合
*     @Caching(evict = {
*             @CacheEvict(value = "category", key = "'getLevel1Categorys'"),
*             @CacheEvict(value = "category", key = "'getCatalogJson'")
*     })
* 方法2：使用直接删除某个分区下的所有数据。@CacheEvict(value = "category",allEntries = true)
```

约定：存储同一类型的数据，都可以指定成为一个分区，默认开始前缀，并且不指定前缀。

#### 4.3 不足

1、回顾原理：org.springframework.data.redis.cache.RedisCache

CacheManager(RedisCacheManager)=>RedisCache=>操作缓存。

2、读模式

- 缓存穿透：查询null数据。
  - 解决：缓存空数据=>spring.cache.redis.cache-null-values=true
- 缓存击穿：大并发同时查询一个正好过期的数据。
  - 解决：加锁?默认使无加锁的。指定同步调用`sync = true`，但是整个类中只有get是存在锁，而且是单机锁。
- 缓存雪崩：大量的key同时过期。
  - 解决：加随机时间，但是可能会弄巧成拙。因此我们直接加上过期时间即可。

3、写模式：缓存与数据库一致。

- 读写加锁。
- 引入Canal，感知mysql的更新去更新数据库。
- 读多写多，直接去数据库查询就行。

4、总结

- 常规数据(读多写少，及时性，一致性要求不高的数据)，只要缓存的数据存在过期时间即可，只要过期了，就触发自动更新。
- 特殊数据：特殊设计。

